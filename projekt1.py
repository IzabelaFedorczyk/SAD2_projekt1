# -*- coding: utf-8 -*-
"""Projekt1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WNp_Y-TV6bm_1dDZoR_TVlqOcZz4UGRL

#### Task 1

(a)
"""

# pip install scanpy

# pip install matplotlib==3.1.3

import scanpy as sc
import anndata as ad
import numpy as np
from scipy.sparse import csr_matrix
import pandas as pd
import matplotlib.pylab as plt

train_data = sc.read_h5ad("/content/drive/MyDrive/MAGISTERKA/SAD2/SAD2022Z_Project1_GEX_train.h5ad")
# print(train_data)
# train_data.obs_names = [f"Cell_{i}" for i in range(train_data.n_obs)]
# train_data.var_names = [f"Gene_{i}" for i in range(train_data.n_vars)]
# print(train_data.obs_names)

test_data = sc.read_h5ad("/content/drive/MyDrive/MAGISTERKA/SAD2/SAD2022Z_Project1_GEX_test.h5ad")
# print(test_data)
# test_data.obs_names = [f"Cell_{i}" for i in range(test_data.n_obs)]
# test_data.var_names = [f"Gene_{i}" for i in range(test_data.n_vars)]
# print(test_data)

print(train_data.n_obs, train_data.n_vars)

print(test_data.n_obs, test_data.n_vars)

"""(b)"""

train_norm = train_data.X.toarray()
train_raw = train_data.layers['counts'].toarray()
test_norm = test_data.X.toarray()
test_raw = test_data.layers['counts'].toarray()

train_norm_clipped = np.clip(train_norm, 0, 20)
train_raw_clipped = np.clip(train_raw, 0, 20)
test_norm_clipped = np.clip(test_norm, 0, 20)
test_raw_clipped = np.clip(test_raw, 0, 20)

fig, axes = plt.subplots(2, 2, figsize = (12, 12))
label_setter = np.vectorize(lambda ax: [ax.set_xlabel('Value'), 
                                   ax.set_ylabel('Frequency')])
axes[0,0].hist(train_norm_clipped.reshape(-1))
axes[0,0].set_title('Preprocessed train data')
axes[0,1].hist(train_raw_clipped.reshape(-1))
axes[0,1].set_title('Raw train data')
axes[1,0].hist(test_norm_clipped.reshape(-1))
axes[1,0].set_title('Preprocessed test data')
axes[1,1].hist(test_raw_clipped.reshape(-1))
axes[1,1].set_title('Raw test data')

label_setter(axes)

fig.show()

"""(c)

Has the data beeen normalized to 10k reads?
"""

train_norm.sum(axis=1)

train_raw.sum(axis=1)

test_norm.sum(axis=1)

test_raw.sum(axis = 1)

"""Answer = NO

Has it been log1p transformed?
"""

train_norm

np.expm1(train_norm)

train_raw

"""Answer = NO

(d)
"""

train_norm = train_norm[train_norm!=0]
train_raw = train_raw[train_raw!=0]
test_norm = test_norm[test_norm!=0]
test_raw = test_raw[test_raw!=0]

train_norm_clipped = np.clip(train_norm, 0, 20)
train_raw_clipped = np.clip(train_raw, 0, 20)
test_norm_clipped = np.clip(test_norm, 0, 20)
test_raw_clipped = np.clip(test_raw, 0, 20)

fig, axes = plt.subplots(2, 2, figsize = (15, 15))
label_setter = np.vectorize(lambda ax: [ax.set_xlabel('Value'), 
                                   ax.set_ylabel('Frequency')])
axes[0,0].hist(train_norm_clipped)
axes[0,0].set_title('Preprocessed train data')
axes[0,1].hist(train_raw_clipped)
axes[0,1].set_title('Raw train data')
axes[1,0].hist(test_norm_clipped)
axes[1,0].set_title('Preprocessed test data')
axes[1,1].hist(test_raw_clipped)
axes[1,1].set_title('Raw test data')


label_setter(axes)
fig.suptitle("Without zeros")
fig.show()

"""(e)

The distribution of data remind of exponential distribution. I assume that the distribution of the data is right-skewed because the data is the data of gene expression mostly from cells of the immune system. As it's more common to be healthy rather that sick (so it's more probable that grater amount of human donors from who the dataset was collected have been healthy) thus most of the genes in our dataset involved in defendence of organism have (not suprisingly) small expression. What's more to extract more valuable information from dataset it's important to remove zero values as because of the same reason I mentioned above there are a lot of them and they make it more difficult to analyse genes with actual expression which are the ones we're probably more interested in. (Zero values noise the information about the actual expression.)

(f)
"""

train_data.obs

test_data.obs

"""The data contained in data frame adata.obs is a detailed information of each observation (for example in our case information such as cell type or BMI of a donor)"""

obs = pd.concat([train_data.obs, test_data.obs])

print("Number of patients: ", len(obs['DonorID'].drop_duplicates()), 
      '\n', 
      "Number of labs: ", len(obs['Site'].drop_duplicates()), 
      '\n', 
      "Number of cell types: ", len(obs['cell_type'].drop_duplicates()))